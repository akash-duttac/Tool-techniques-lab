{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 11 | Data Preprocessing Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Akash Duttachowdhury\n",
    "### 21052386"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For file: data.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEjpRF5cRT4v"
   },
   "source": [
    "**Importing the dataset data.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wCMkdHiFRT40",
    "outputId": "4ba65751-b9b0-4514-d5cf-9bd8d05e330b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Age</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>44.0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Spain</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Spain</td>\n",
       "      <td>38.0</td>\n",
       "      <td>61000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>40.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>France</td>\n",
       "      <td>35.0</td>\n",
       "      <td>58000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>France</td>\n",
       "      <td>48.0</td>\n",
       "      <td>79000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Germany</td>\n",
       "      <td>50.0</td>\n",
       "      <td>83000.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>France</td>\n",
       "      <td>37.0</td>\n",
       "      <td>67000.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Country   Age   Salary Purchased\n",
       "0   France  44.0  72000.0        No\n",
       "1    Spain  27.0  48000.0       Yes\n",
       "2  Germany  30.0  54000.0        No\n",
       "3    Spain  38.0  61000.0        No\n",
       "4  Germany  40.0      NaN       Yes\n",
       "5   France  35.0  58000.0       Yes\n",
       "6    Spain   NaN  52000.0        No\n",
       "7   France  48.0  79000.0       Yes\n",
       "8  Germany  50.0  83000.0        No\n",
       "9   France  37.0  67000.0       Yes"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the datasets\n",
    "dataset = pd.read_csv('Data.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "omXDId_ERT40"
   },
   "outputs": [],
   "source": [
    "X = dataset.iloc[:,:-1].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FeGHIbHeRT41"
   },
   "source": [
    "Replace the missing value with column mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "a1ENxE5TRT41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X after imputation:\n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]]\n"
     ]
    }
   ],
   "source": [
    "# Taking care of missing data\n",
    "from sklearn.impute import SimpleImputer\n",
    "# Initialize the SimpleImputer with mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Fit and transform the imputer on the data\n",
    "X[:, 1:3] = imputer.fit_transform(X[:, 1:3])\n",
    "\n",
    "# Print the first few rows of X after imputation\n",
    "print(\"X after imputation:\")\n",
    "print(X[:5])  # Print the first 5 rows for demonstration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVbR86qART43"
   },
   "source": [
    "Replace the missing value with constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nGLwElwORT43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X after imputation:\n",
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the SimpleImputer with mean strategy\n",
    "imputer = SimpleImputer(strategy='constant', fill_value=69000)\n",
    "\n",
    "# Fit and transform the imputer on the data\n",
    "X[:, 1:3] = imputer.fit_transform(X[:, 1:3])\n",
    "\n",
    "# Print the first few rows of X after imputation\n",
    "print(\"X after imputation:\")\n",
    "print(X[:5])  # Print the first 5 rows for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q37MOkX-RT43"
   },
   "source": [
    "Encoding the Independent Variable with OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "HzIZc08qRT44",
    "outputId": "702d5786-86fb-44ef-c553-2d7c7c3c9fe5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_encoded: (10, 5)\n",
      "Sample of X_encoded:\n",
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Creating a pipeline for preprocessing\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('encoder', OneHotEncoder(), [0])  # Apply OneHotEncoder to column at index 0\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the remaining columns as they are\n",
    ")\n",
    "\n",
    "# Fit and transform the data using the pipeline\n",
    "X_encoded = preprocessor.fit_transform(X)\n",
    "\n",
    "# Print the shape and a sample of the encoded X\n",
    "print(\"Shape of X_encoded:\", X_encoded.shape)\n",
    "print(\"Sample of X_encoded:\")\n",
    "print(X_encoded[:5])  # Print the first 5 rows for demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XkS0MctJRT45"
   },
   "source": [
    "Encoding the Dependent Variable with LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Creating the object of LabelEncoder class\n",
    "labelencoder_y = LabelEncoder()\n",
    "\n",
    "# fit labelencoder_y object to last coulmn Purchased, we will get encoded vector\n",
    "y = labelencoder_y.fit_transform(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHsClYU2RT47"
   },
   "source": [
    "Splitting the dataset into the 80: 20 Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xpEqaIkTRT47"
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Choosing 20% data as test data, so we will have 80% data in training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVSVOh4oRT49"
   },
   "source": [
    "Perform Feature Scaling using Column-normalization (Hints: use MinMaxScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "vEfCZ7CxRT49"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "sc_X = MinMaxScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For file: iris.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pj4bxt_qRT49"
   },
   "source": [
    "load iris.csv dataset and locate rows of duplicate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5.1</th>\n",
       "      <th>3.5</th>\n",
       "      <th>1.4</th>\n",
       "      <th>0.2</th>\n",
       "      <th>Iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     5.1  3.5  1.4  0.2     Iris-setosa\n",
       "0    4.9  3.0  1.4  0.2     Iris-setosa\n",
       "1    4.7  3.2  1.3  0.2     Iris-setosa\n",
       "2    4.6  3.1  1.5  0.2     Iris-setosa\n",
       "3    5.0  3.6  1.4  0.2     Iris-setosa\n",
       "4    5.4  3.9  1.7  0.4     Iris-setosa\n",
       "..   ...  ...  ...  ...             ...\n",
       "144  6.7  3.0  5.2  2.3  Iris-virginica\n",
       "145  6.3  2.5  5.0  1.9  Iris-virginica\n",
       "146  6.5  3.0  5.2  2.0  Iris-virginica\n",
       "147  6.2  3.4  5.4  2.3  Iris-virginica\n",
       "148  5.9  3.0  5.1  1.8  Iris-virginica\n",
       "\n",
       "[149 rows x 5 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = pd.read_csv('iris.csv')\n",
    "iris_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "144    False\n",
      "145    False\n",
      "146    False\n",
      "147    False\n",
      "148    False\n",
      "Length: 149, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "duplicates = iris_data.duplicated()\n",
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gqmpi9C4RT4-"
   },
   "source": [
    "Delete duplicate rows in iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "w3mtBsdIRT4-",
    "outputId": "f32e649c-0c8b-4065-d097-2f639f42ebed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(149, 5)\n",
      "(146, 5)\n"
     ]
    }
   ],
   "source": [
    "print(iris_data.shape)\n",
    "iris = iris_data.drop_duplicates()\n",
    "print(iris.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5pnswW04RT4-"
   },
   "source": [
    "load and summarize the pima-indians-diabetes.csv dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "y7ZfvpvART4-",
    "outputId": "5bfa5ba7-2ef9-4afe-8cdf-b2e4f077f820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 767 entries, 0 to 766\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   6       767 non-null    int64  \n",
      " 1   148     767 non-null    int64  \n",
      " 2   72      767 non-null    int64  \n",
      " 3   35      767 non-null    int64  \n",
      " 4   0       767 non-null    int64  \n",
      " 5   33.6    767 non-null    float64\n",
      " 6   0.627   767 non-null    float64\n",
      " 7   50      767 non-null    int64  \n",
      " 8   1       767 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "pid = pd.read_csv('pima-indians-diabetes.csv')\n",
    "pid.shape\n",
    "pid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-IM7Yap7RT4_"
   },
   "source": [
    "Count the number of missing values for each column (In this dataset 0 is treated as missing value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 0 with NaN in the entire DataFrame\n",
    "pid.replace(0, np.NaN, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6        111\n",
       "148        5\n",
       "72        35\n",
       "35       227\n",
       "0        373\n",
       "33.6      11\n",
       "0.627      0\n",
       "50         0\n",
       "1        500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of missing values (NaN) in each column\n",
    "missing_values_count = pid.isnull().sum()\n",
    "missing_values_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uB6mwnHkRT4_"
   },
   "source": [
    "drop rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "xi0aJi0eRT4_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(767, 9)\n",
      "(111, 9)\n"
     ]
    }
   ],
   "source": [
    "print(pid.shape)\n",
    "pid.dropna(inplace=True)\n",
    "print(pid.shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
